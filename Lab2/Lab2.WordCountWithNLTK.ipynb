{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.1. Get Started with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\navar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt') \n",
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_tokens():\n",
    "    with open('t8.shakespeare.txt', 'r') as tf:\n",
    "        text = tf.read()\n",
    "        tokens = nltk.word_tokenize(text.encode('utf-8'))\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1. Word Count 1\n",
    "Here we consider the punctuation signs either as words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 83170), ('.', 76936), ('the', 23259), ('I', 21945), ('and', 18592), (';', 17199), ('to', 15839), ('of', 15706), ('a', 12574), ('you', 12110)]\n"
     ]
    }
   ],
   "source": [
    "tokens = get_tokens()\n",
    "count = Counter(tokens)\n",
    "print count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2. Word Count 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1131191"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.3. Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 27643), ('and', 26728), ('i', 20681), ('to', 19198), ('of', 18173), ('a', 14613), ('you', 13649), ('my', 12480), ('that', 11121), ('in', 10967)]\n"
     ]
    }
   ],
   "source": [
    "def get_tokens():\n",
    "    with open('t8.shakespeare.txt', 'r') as tf:\n",
    "        text = tf.read()\n",
    "        lowers = text.lower()\n",
    "        no_punctuation = lowers.translate(None, string.punctuation)\n",
    "        tokens = nltk.word_tokenize(no_punctuation)\n",
    "        return tokens\n",
    "\n",
    "tokens = get_tokens()\n",
    "count = Counter(tokens)\n",
    "print count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.4. Stop words\n",
    "Stop words are those words (different for every language) which, usually, do not add any meaning to the text. They are words like articles, prepositions, etc. They normally are discarted in a NLP process, with the exception of phrases analysis engines in which some of these words may take the form of a noun, for instance. In this latter case, they do have a clear meaning, so they would be included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to install all the corpora packages in order to use the nltk.corpus hereafter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Remember to close the window that the previous command has launched. If not, the execution will pause and will not resume until it is closed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokens = get_tokens()\n",
    "filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "count = Counter(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thou', 5485), ('thy', 4032), ('shall', 3591), ('thee', 3178), ('lord', 3059), ('king', 2861), ('good', 2812), ('sir', 2754), ('come', 2507), ('well', 2462)]\n"
     ]
    }
   ],
   "source": [
    "print count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(What a vocabulary!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
